{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3aa749bb",
   "metadata": {},
   "source": [
    "**Phase 3: Implement Retrieval-Augmented Generation (RAG)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995c39c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "142465b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03bd1a33de6044ef8a161a31a3422fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "187da816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\AppData\\Local\\Temp\\ipykernel_38964\\1599606810.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\krish\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\krish\\AppData\\Local\\Temp\\ipykernel_38964\\1599606810.py:2: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectorstore = Chroma(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks loaded from 'database': 1731\n"
     ]
    }
   ],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "vectorstore = Chroma(\n",
    "    collection_name=\"database\",\n",
    "    embedding_function=embedding_model,\n",
    "    persist_directory=\"database\"\n",
    ")\n",
    "vectorstore._collection\n",
    "num_chunks = len(vectorstore.get()[\"ids\"])\n",
    "print(f\"Number of chunks loaded from 'database': {num_chunks}\")\n",
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d1667a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.2-1B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.float16\n",
    ")\n",
    "llama = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1a61bb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_prompt_template = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant with deep chess knowledge.you are given a context and a question.\n",
    "Use the following context to answer the user query:\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User: {question}\n",
    "Answer:\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bac877b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rag_chat(query: str):\n",
    "    docs = retriever.get_relevant_documents(query)\n",
    "    context = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "    prompt = rag_prompt_template.format(context=context, question=query)\n",
    "\n",
    "    output = llama(prompt)[0][\"generated_text\"]\n",
    "    \n",
    "    if prompt in output:\n",
    "        output = output.replace(prompt, \"\").strip()\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "75383826",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ’¬ Castling is a move that allows you to protect your king and use your rook. Once all the squares between your rook and the king are free, you can move the king two square toward the square where the rook is while the rook moves to the square on the kingâ€™s other side. Look for an opportunity when your opponent disregards to castle, this is when you can launch an attack on the opponentâ€™s king. This move is the only way where more than a single piece can be moved in a single move/turn.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"What is Castling?\"\n",
    "response = rag_chat(user_query)\n",
    "print(\"ðŸ’¬\", response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
